<!--<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Sagun Pai</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Sagun Pai</name>
        </p>
        <p>I am a senior research scientist at <a href="https://research.google.com/">Google Research</a>, where I work on computer vision and computational photography. At Google I've worked on <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="http://googleresearch.blogspot.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://research.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>.
        </p>
        <p>
          I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've spent time at <a href="https://en.wikipedia.org/wiki/Google_X">Google[x]</a>, <a href="http://groups.csail.mit.edu/vision/welcome/">MIT CSAIL</a>, <a href="http://www.captricity.com/">Captricity</a>, <a href="https://www.nasa.gov/ames">NASA Ames</a>, <a href="http://www.google.com/">Google NYC</a>, the <a href="http://mrl.nyu.edu/">NYU MRL</a>, <a href="http://www.nibr.com/">Novartis</a>, and <a href="http://www.astrometry.net/">Astrometry.net</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
        </p>
        <p align=center>
          <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
          <a href="cv.pdf">CV</a> &nbsp/&nbsp
          <a href="JonBarron-bio.txt">Biography</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href="http://www.linkedin.com/in/jonathanbarron/"> LinkedIn </a>
        </p>
        </td>
        <td width="33%">
        <img src="JonBarron_circle.jpg">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>
          I'm interested in computer vision, machine learning, statistics, optimization, image processing, virtual reality, and computational photography. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. I have also worked in astronomy and biology. Representative papers are <span class="highlight">highlighted</span>.
          </p>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='aperture_after.jpg'></div>
        <img src='aperture_before.jpg'>
        </div>
        <script type="text/javascript">
        function aperture_start() {
        document.getElementById('aperture_image').style.opacity = "1";
        }
        function aperture_stop() {
        document.getElementById('aperture_image').style.opacity = "0";
        }
        aperture_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://arxiv.org/abs/1711.07933">
            <papertitle>Aperture Supervision for Monocular Depth Estimation</papertitle>
	  </a>
	  <br>
          <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>,
	  <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
	  <a href="http://people.csail.mit.edu/nwadhwa/">Neal Wadhwa</a>,
	  <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
	  <strong>Jonathan T. Barron</strong> <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>
        <p></p>
        <p>Varying a camera's aperture provides a supervisory signal that can teach a neural network to do monocular depth estimation.</p>
      </td>
    </tr>
		
    <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'deepburst_image'><img src='deepburst_after.png'></div>
        <img src='deepburst_before.png'>
        </div>
        <script type="text/javascript">
        function deepburst_start() {
        document.getElementById('deepburst_image').style.opacity = "1";
        }
        function deepburst_stop() {
        document.getElementById('deepburst_image').style.opacity = "0";
        }
        deepburst_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://arxiv.org/abs/1712.02327">
        <papertitle>Burst Denoising with Kernel Prediction Networks</papertitle>
        </a>
        <br>
        <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
        Dillon Sharlet,
        <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
        Robert Carroll <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>
        <p></p>
        <p>We train a network to predict linear kernels that denoise noisy bursts from cellphone cameras.</p>
      </td>
    </tr>
	  
    <tr onmouseout="friendly_stop()" onmouseover="friendly_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'friendly_image'><img src='friendly_after.png'></div>
        <img src='friendly_before.png'>
        </div>
        <script type="text/javascript">
        function friendly_start() {
        document.getElementById('friendly_image').style.opacity = "1";
        }
        function friendly_stop() {
        document.getElementById('friendly_image').style.opacity = "0";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
        <papertitle>A Hardware-Friendly Bilateral Solver for Real-Time Virtual Reality Video</papertitle></a><br>
          <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>  <br>
        <em>High-Performance Graphics (HPG)</em>, 2017 <br>
        <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
        <p></p>
        <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
      </td>
    </tr>

    <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'hdrnet_image'><img src='hdrnet_after.jpg'></div>
        <img src='hdrnet_before.jpg'>
        </div>
        <script type="text/javascript">
        function hdrnet_start() {
        document.getElementById('hdrnet_image').style.opacity = "1";
        }
        function hdrnet_stop() {
        document.getElementById('hdrnet_image').style.opacity = "0";
        }
        hdrnet_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://drive.google.com/file/d/1jQY3CTMnLX7PeGUzYLso9H1eCsZyWbwg/view?usp=sharing">
        <papertitle>Deep Bilateral Learning for Real-Time Image Enhancement</papertitle></a><br>
          <a href="http://www.mgharbi.com">Micha&euml;l Gharbi</a>, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, <a href="http://people.csail.mit.edu/fredo/">Fr&eacute;do Durand </a> <br>
        <em>SIGGRAPH</em>, 2017 <br>
        <a href="https://groups.csail.mit.edu/graphics/hdrnet/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=GAe0qKKQY_I">video</a>
        /
        <a href="GharbiSIGGRAPH2017.bib">bibtex</a>
        /
        <a href="http://news.mit.edu/2017/automatic-image-retouching-phone-0802">p</a><a href="https://www.wired.com/story/googles-new-algorithm-perfects-photos-before-you-even-take-them/">r</a><a href="https://petapixel.com/2017/08/02/new-ai-can-retouch-photos-snap/">e</a><a href="https://www.theverge.com/2017/8/2/16082272/google-mit-retouch-photos-machine-learning">s</a><a href="http://gizmodo.com/clever-camera-app-uses-deep-learning-to-perfectly-retou-1797474282">s</a>
        <p></p>
        <p>By training a deep network in bilateral space we can learn a model for high-resolution and real-time image enhancement.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <img src='loss.png'>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1701.03077">
          <papertitle>A More General Robust Loss Function</papertitle></a><br>
          <strong>Jonathan T. Barron</strong> <br>
          <em>arXiv Preprint</em>, 2017 <br>
	  <p></p>
          <p>A single robust loss function is a superset of many other common robust loss functions.</p>
        </td>
      </tr>

      <tr>
        <td width="25%"><img src="clean_promo.jpg" alt="clean-usnob" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
        <p>
          <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
          <papertitle>Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a><br>
          <em>The Astronomical Journal</em>, 135, 2008
        </p>
        <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
        <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a><br>
          <br>
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Course Projects</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="prl.jpg" alt="prl" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="https://drive.google.com/file/d/13rVuJpcytRdLYCnKpq46g7B7IzSrPQ2P/view?usp=sharing">
          <papertitle>Parallelizing Reinforcement Learning</papertitle>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/~dsg/">Dave Golland</a>, <a href="http://www.cs.berkeley.edu/~nickjhay/">Nicholas J. Hay</a>, 2009
        <p><br>
          Markov Decision Problems which lie in a low-dimensional latent space can be decomposed, allowing modified RL algorithms to run orders of magnitude faster in parallel.
        </p>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="pacman.jpg" alt="pacman" width="160" height="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
          <papertitle>CS188 - Fall 2010 (GSI)</papertitle>
          </a>
          <br><br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
          <papertitle>CS188 - Spring 2011 (GSI)</papertitle>
          </a>
          <br>
        </p>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website"><strong>source code</strong></a>, just add a link back to my website. Send me an email when you're done and I'll link to your new page from here:
          <a href="https://cs.stanford.edu/~poole/">&#10025;</a>
          <a href="http://www.cs.berkeley.edu/~akar/">&#10025;</a>
          <a href="http://www.eecs.berkeley.edu/~biancolin">&#10025;</a>
          <a href="http://www.rossgirshick.info/">&#10025;</a>
	    </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
-->

<html>
	<h1> Hello </h1>
	
	
</html>
